{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Extensions to Linear Models - Lab"]},{"cell_type":"markdown","metadata":{},"source":["## Introduction\n","\n","In this lab, you'll practice many concepts you have learned so far, from adding interactions and polynomials to your model to regularization!"]},{"cell_type":"markdown","metadata":{},"source":["## Summary\n","\n","You will be able to:\n","\n","- Build a linear regression model with interactions and polynomial features \n","- Use feature selection to obtain the optimal subset of features in a dataset"]},{"cell_type":"markdown","metadata":{},"source":["## Let's Get Started!\n","\n","Below we import all the necessary packages for this lab."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# Run this cell without changes\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.filterwarnings('ignore')\n","from itertools import combinations\n","\n","from sklearn.feature_selection import RFE\n","from sklearn.linear_model import LinearRegression, Lasso\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, PolynomialFeatures"]},{"cell_type":"markdown","metadata":{},"source":["Load the data."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Run this cell without changes\n","\n","# Load data from CSV\n","df = pd.read_csv(\"ames.csv\")\n","# Subset columns\n","df = df[['LotArea', 'OverallQual', 'OverallCond', 'TotalBsmtSF',\n","         '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'TotRmsAbvGrd',\n","         'GarageArea', 'Fireplaces', 'SalePrice']]\n","\n","# Split the data into X and y\n","y = df['SalePrice']\n","X = df.drop(columns='SalePrice')\n","\n","# Split into train, test, and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42)\n","X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, random_state=0)"]},{"cell_type":"markdown","metadata":{},"source":["## Build a Baseline Housing Data Model"]},{"cell_type":"markdown","metadata":{},"source":["Above, we imported the Ames housing data and grabbed a subset of the data to use in this analysis.\n","\n","Next steps:\n","\n","- Scale all the predictors using `StandardScaler`, then convert these scaled features back into DataFrame objects\n","- Build a baseline `LinearRegression` model using *scaled variables* as predictors and use the $R^2$ score to evaluate the model "]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Your code here\n","\n","# Instatiate Scaler \n","scaler = StandardScaler()\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# Scale X_train and X_test using StandardScaler\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Ensure X_train and X_test are scaled DataFrames\n","X_train = pd.DataFrame(X_train_scaled, columns=X.columns)\n","X_test = pd.DataFrame(X_test_scaled, columns=X.columns)\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LotArea</th>\n","      <th>OverallQual</th>\n","      <th>OverallCond</th>\n","      <th>TotalBsmtSF</th>\n","      <th>1stFlrSF</th>\n","      <th>2ndFlrSF</th>\n","      <th>GrLivArea</th>\n","      <th>TotRmsAbvGrd</th>\n","      <th>GarageArea</th>\n","      <th>Fireplaces</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.114710</td>\n","      <td>-0.099842</td>\n","      <td>-0.509252</td>\n","      <td>-0.639316</td>\n","      <td>-0.804789</td>\n","      <td>1.261552</td>\n","      <td>0.499114</td>\n","      <td>0.250689</td>\n","      <td>0.327629</td>\n","      <td>-0.994820</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.176719</td>\n","      <td>0.632038</td>\n","      <td>-0.509252</td>\n","      <td>0.838208</td>\n","      <td>0.641608</td>\n","      <td>-0.808132</td>\n","      <td>-0.247249</td>\n","      <td>-0.365525</td>\n","      <td>0.079146</td>\n","      <td>-0.994820</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.246336</td>\n","      <td>-0.831723</td>\n","      <td>1.304613</td>\n","      <td>-0.012560</td>\n","      <td>-0.329000</td>\n","      <td>-0.808132</td>\n","      <td>-0.944766</td>\n","      <td>-0.981739</td>\n","      <td>-1.105931</td>\n","      <td>-0.994820</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.378617</td>\n","      <td>-0.831723</td>\n","      <td>1.304613</td>\n","      <td>-0.339045</td>\n","      <td>-0.609036</td>\n","      <td>-0.808132</td>\n","      <td>-1.146010</td>\n","      <td>-0.981739</td>\n","      <td>-1.134602</td>\n","      <td>0.588023</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.010898</td>\n","      <td>-1.563603</td>\n","      <td>1.304613</td>\n","      <td>-2.531499</td>\n","      <td>-1.315922</td>\n","      <td>0.550523</td>\n","      <td>-0.481708</td>\n","      <td>0.250689</td>\n","      <td>-2.281450</td>\n","      <td>-0.994820</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    LotArea  OverallQual  OverallCond  TotalBsmtSF  1stFlrSF  2ndFlrSF  \\\n","0 -0.114710    -0.099842    -0.509252    -0.639316 -0.804789  1.261552   \n","1 -0.176719     0.632038    -0.509252     0.838208  0.641608 -0.808132   \n","2 -0.246336    -0.831723     1.304613    -0.012560 -0.329000 -0.808132   \n","3 -0.378617    -0.831723     1.304613    -0.339045 -0.609036 -0.808132   \n","4 -0.010898    -1.563603     1.304613    -2.531499 -1.315922  0.550523   \n","\n","   GrLivArea  TotRmsAbvGrd  GarageArea  Fireplaces  \n","0   0.499114      0.250689    0.327629   -0.994820  \n","1  -0.247249     -0.365525    0.079146   -0.994820  \n","2  -0.944766     -0.981739   -1.105931   -0.994820  \n","3  -1.146010     -0.981739   -1.134602    0.588023  \n","4  -0.481708      0.250689   -2.281450   -0.994820  "]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# (hint: you can set the columns using X.columns)\n","X_train.head()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LotArea</th>\n","      <th>OverallQual</th>\n","      <th>OverallCond</th>\n","      <th>TotalBsmtSF</th>\n","      <th>1stFlrSF</th>\n","      <th>2ndFlrSF</th>\n","      <th>GrLivArea</th>\n","      <th>TotRmsAbvGrd</th>\n","      <th>GarageArea</th>\n","      <th>Fireplaces</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.491264</td>\n","      <td>-0.099842</td>\n","      <td>0.397681</td>\n","      <td>-0.248487</td>\n","      <td>-0.598161</td>\n","      <td>-0.808132</td>\n","      <td>-1.138195</td>\n","      <td>-0.981739</td>\n","      <td>-0.178895</td>\n","      <td>-0.994820</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.619291</td>\n","      <td>0.632038</td>\n","      <td>-0.509252</td>\n","      <td>-0.205591</td>\n","      <td>-0.549222</td>\n","      <td>0.849426</td>\n","      <td>0.327177</td>\n","      <td>0.250689</td>\n","      <td>-0.465607</td>\n","      <td>-0.994820</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.240165</td>\n","      <td>-0.099842</td>\n","      <td>0.397681</td>\n","      <td>-0.639316</td>\n","      <td>-1.044043</td>\n","      <td>0.722619</td>\n","      <td>-0.137834</td>\n","      <td>-0.365525</td>\n","      <td>-0.427379</td>\n","      <td>-0.994820</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.037695</td>\n","      <td>2.095798</td>\n","      <td>-3.230050</td>\n","      <td>1.891539</td>\n","      <td>1.843314</td>\n","      <td>-0.808132</td>\n","      <td>0.616344</td>\n","      <td>0.866903</td>\n","      <td>1.703847</td>\n","      <td>0.588023</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.147924</td>\n","      <td>0.632038</td>\n","      <td>-0.509252</td>\n","      <td>-1.616388</td>\n","      <td>-0.995104</td>\n","      <td>0.709032</td>\n","      <td>-0.114388</td>\n","      <td>0.250689</td>\n","      <td>-0.408265</td>\n","      <td>0.588023</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    LotArea  OverallQual  OverallCond  TotalBsmtSF  1stFlrSF  2ndFlrSF  \\\n","0 -0.491264    -0.099842     0.397681    -0.248487 -0.598161 -0.808132   \n","1 -0.619291     0.632038    -0.509252    -0.205591 -0.549222  0.849426   \n","2  0.240165    -0.099842     0.397681    -0.639316 -1.044043  0.722619   \n","3  0.037695     2.095798    -3.230050     1.891539  1.843314 -0.808132   \n","4 -0.147924     0.632038    -0.509252    -1.616388 -0.995104  0.709032   \n","\n","   GrLivArea  TotRmsAbvGrd  GarageArea  Fireplaces  \n","0  -1.138195     -0.981739   -0.178895   -0.994820  \n","1   0.327177      0.250689   -0.465607   -0.994820  \n","2  -0.137834     -0.365525   -0.427379   -0.994820  \n","3   0.616344      0.866903    1.703847    0.588023  \n","4  -0.114388      0.250689   -0.408265    0.588023  "]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["X_test.head()"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["R^2: 0.7868344817421309\n"]}],"source":["# Your code here\n","\n","# Create a LinearRegression model and fit it on scaled training data\n","# Instantiate LinerRegression\n","linreg = LinearRegression()\n","\n","# Fit the model\n","linreg.fit(X_train, y_train)\n","# Calculate a baseline r-squared score on training data\n","baseline = linreg.score(X_train, y_train)\n","print(\"R^2:\", baseline)"]},{"cell_type":"markdown","metadata":{},"source":["## Add Interactions\n","\n","Instead of adding all possible interaction terms, let's try a custom technique. We are only going to add the interaction terms that increase the $R^2$ score as much as possible. Specifically we are going to look for the 7 interaction terms that each cause the most increase in the coefficient of determination.\n","\n","### Find the Best Interactions\n","\n","Look at all the possible combinations of variables for interactions by adding interactions one by one to the baseline model. Create a data structure that stores the pair of columns used as well as the $R^2$ score for each combination.\n","\n","***Hint:*** We have imported the `combinations` function from `itertools` for you ([documentation here](https://docs.python.org/3/library/itertools.html#itertools.combinations)). Try applying this to the columns of `X_train` to find all of the possible pairs.\n","\n","Print the 7 interactions that result in the highest $R^2$ scores."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here\n","\n","# Set up data structure\n","\n","\n","# Find combinations of columns and loop over them\n","\n","    # Make copies of X_train and X_test\n","    \n","    \n","    # Add interaction term to data\n","\n","    \n","    # Find r-squared score (fit on training data, evaluate on test data)\n","\n","    \n","    # Append to data structure\n","    \n","    \n","# Sort and subset the data structure to find the top 7\n"]},{"cell_type":"markdown","metadata":{},"source":["### Add the Best Interactions\n","\n","Write code to include the 7 most important interactions in `X_train` and `X_test` by adding 7 columns. Use the naming convention `\"col1_col2\"`, where `col1` and `col2` are the two columns in the interaction."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here\n","\n","# Loop over top 7 interactions\n","\n","    # Extract column names from data structure\n","\n","    # Construct new column name\n","    \n","    # Add new column to X_train and X_test\n"]},{"cell_type":"markdown","metadata":{},"source":["## Add Polynomials\n","\n","Now let's repeat that process for adding polynomial terms.\n","\n","### Find the Best Polynomials\n","\n","Try polynomials of degrees 2, 3, and 4 for each variable, in a similar way you did for interactions (by looking at your baseline model and seeing how $R^2$ increases). Do understand that when going for a polynomial of degree 4 with `PolynomialFeatures`, the particular column is raised to the power of 2 and 3 as well in other terms.\n","\n","We only want to include \"pure\" polynomials, so make sure no interactions are included.\n","\n","Once again you should make a data structure that contains the values you have tested. We recommend a list of tuples of the form:\n","\n","`(col_name, degree, R2)`, so eg. `('OverallQual', 2, 0.781)` "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here\n","\n","# Set up data structure\n","\n","# Loop over all columns\n","\n","    # Loop over degrees 2, 3, 4\n","        \n","        # Make a copy of X_train and X_test\n","    \n","        # Instantiate PolynomialFeatures with relevant degree\n","        \n","        # Fit polynomial to column and transform column\n","        # Hint: use the notation df[[column_name]] to get the right shape\n","        # Hint: convert the result to a DataFrame\n","        \n","        # Add polynomial to data\n","        # Hint: use pd.concat since you're combining two DataFrames\n","        # Hint: drop the column before combining so it doesn't appear twice\n","    \n","        # Find r-squared score\n","    \n","        # Append to data structure\n","\n","# Sort and subset the data structure to find the top 7\n"]},{"cell_type":"markdown","metadata":{},"source":["### Add the Best Polynomials\n","\n","If there are duplicate column values in the results above, don't add multiple of them to the model, to avoid creating duplicate columns. (For example, if column `A` appeared in your list as both a 2nd and 3rd degree polynomial, adding both would result in `A` squared being added to the features twice.) Just add in the polynomial that results in the highest R-Squared."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here\n","\n","# Filter out duplicates\n","\n","# Loop over remaining results\n","\n","    # Create polynomial terms\n","    \n","    # Concat new polynomials to X_train and X_test\n","    "]},{"cell_type":"markdown","metadata":{},"source":["Check out your final data set and make sure that your interaction terms as well as your polynomial terms are included."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here"]},{"cell_type":"markdown","metadata":{},"source":["## Full Model R-Squared"]},{"cell_type":"markdown","metadata":{},"source":["Check out the $R^2$ of the full model with your interaction and polynomial terms added. Print this value for both the train and test data."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here"]},{"cell_type":"markdown","metadata":{},"source":["It looks like we may be overfitting some now. Let's try some feature selection techniques."]},{"cell_type":"markdown","metadata":{},"source":["## Feature Selection\n","\n","First, test out `RFE` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html)) with several different `n_features_to_select` values. For each value, print out the train and test $R^2$ score and how many features remain."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here\n"]},{"cell_type":"markdown","metadata":{},"source":["Now test out `Lasso` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)) with several different `alpha` values."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here\n"]},{"cell_type":"markdown","metadata":{},"source":["Compare the results. Which features would you choose to use?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your written answer here"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluate Final Model on Validation Data\n","\n","### Data Preparation\n","\n","At the start of this lab, we created `X_val` and `y_val`. Prepare `X_val` the same way that `X_train` and `X_test` have been prepared. This includes scaling, adding interactions, and adding polynomial terms."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here\n"]},{"cell_type":"markdown","metadata":{},"source":["### Evaluation"]},{"cell_type":"markdown","metadata":{},"source":["Using either `RFE` or `Lasso`, fit a model on the complete train + test set, then find R-Squared and MSE values for the validation set."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here\n"]},{"cell_type":"markdown","metadata":{},"source":["## Level Up Ideas (Optional)\n","\n","### Create a Lasso Path\n","\n","From this section, you know that when using `Lasso`, more parameters shrink to zero as your regularization parameter goes up. In scikit-learn there is a function `lasso_path()` which visualizes the shrinkage of the coefficients while $alpha$ changes. Try this out yourself!\n","\n","https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py\n","\n","### AIC and BIC for Subset Selection\n","\n","This notebook shows how you can use AIC and BIC purely for feature selection. Try this code out on our Ames housing data!\n","\n","https://xavierbourretsicotte.github.io/subset_selection.html"]},{"cell_type":"markdown","metadata":{},"source":["## Summary"]},{"cell_type":"markdown","metadata":{},"source":["Congratulations! You now know how to apply concepts of bias-variance tradeoff using extensions to linear models and feature selection."]}],"metadata":{"kernelspec":{"display_name":"learn-env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":2}
